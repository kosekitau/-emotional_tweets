{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer_TEC.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWmxfK5zgbUI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "da3f858d-1557-4bec-a807-87d30d2c7f94"
      },
      "source": [
        "import string\n",
        "import re\n",
        "\n",
        "# 以下の記号はスペースに置き換えます（カンマ、ピリオドを除く）。\n",
        "# punctuationとは日本語で句点という意味です\n",
        "print(\"区切り文字：\", string.punctuation)\n",
        "# !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
        "\n",
        "# 前処理\n",
        "\n",
        "\n",
        "def preprocessing_text(text):\n",
        "    # 改行コードを消去\n",
        "    text = re.sub('<br />', '', text)\n",
        "\n",
        "    # カンマ、ピリオド以外の記号をスペースに置換\n",
        "    for p in string.punctuation:\n",
        "        if (p == \".\") or (p == \",\"):\n",
        "            continue\n",
        "        else:\n",
        "            text = text.replace(p, \" \")\n",
        "\n",
        "    # ピリオドなどの前後にはスペースを入れておく\n",
        "    text = text.replace(\".\", \" . \")\n",
        "    text = text.replace(\",\", \" , \")\n",
        "    return text\n",
        "\n",
        "# 分かち書き（今回はデータが英語で、簡易的にスペースで区切る）\n",
        "\n",
        "\n",
        "def tokenizer_punctuation(text):\n",
        "    return text.strip().split()\n",
        "\n",
        "\n",
        "# 前処理と分かち書きをまとめた関数を定義\n",
        "def tokenizer_with_preprocessing(text):\n",
        "    text = preprocessing_text(text)\n",
        "    ret = tokenizer_punctuation(text)\n",
        "    return ret\n",
        "\n",
        "\n",
        "# 動作を確認します\n",
        "print(tokenizer_with_preprocessing('I like cats.'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "区切り文字： !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "['I', 'like', 'cats', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDXcwehfgv2l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "40d91d21-660d-44a6-fd18-095da913ab5d"
      },
      "source": [
        "import torchtext\n",
        "\n",
        "max_length = 142\n",
        "TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer_with_preprocessing, \n",
        "                            use_vocab=True, \n",
        "                            lower=True, include_lengths=True, batch_first=True,\n",
        "                            fix_length=max_length, init_token='<cls>',\n",
        "                            eos_token='<eos>')\n",
        "\n",
        "LABEL = torchtext.data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "train_ds, val_ds, test_ds = torchtext.data.TabularDataset.splits(\n",
        "    path='drive/My Drive/dataset/TEC/train_test/', train='train.csv', \n",
        "    validation='val.csv', test='test.csv', format='csv', fields=[('text', TEXT), ('Label', LABEL)]\n",
        ")\n",
        "\n",
        "#分かち書きや正規化などが終了している\n",
        "print(len(train_ds))\n",
        "print(vars(train_ds[0]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17050\n",
            "{'text': ['great', 'start', 'to', 'the', 'day', 'because', 'of', 'an', 'awesome', 'brother', 'and', 'a', 'great', 'god', 'thankful', 'gobblegobble'], 'Label': '3'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwDwlik2i3bE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "597814f6-0193-4c61-8aeb-dd27eb42c494"
      },
      "source": [
        "from torchtext.vocab import Vectors\n",
        "\n",
        "english_fasttext_vectors = Vectors(name='drive/My Drive/wiki-news-300d-1M.vec')\n",
        "\n",
        "print(english_fasttext_vectors.dim)\n",
        "print(len(english_fasttext_vectors.itos))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/999994 [00:00<?, ?it/s]Skipping token b'999994' with 1-dimensional vector [b'300']; likely a header\n",
            "100%|█████████▉| 999608/999994 [02:10<00:00, 7461.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "300\n",
            "999994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umSn6La7i6PB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46bce590-f1fe-49e8-89c9-43b3b2a6b753"
      },
      "source": [
        "#ボキャブラリを作成、最低でも10回以上出現している単語\n",
        "TEXT.build_vocab(train_ds, vectors=english_fasttext_vectors, min_freq=2)\n",
        "print(TEXT.vocab.vectors.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([9878, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4GkxjrYjocL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "2fccebe4-3450-4d9e-9e8f-a794af49645e"
      },
      "source": [
        "train_dl = torchtext.data.Iterator(train_ds, batch_size=64, train=True)\n",
        "val_dl = torchtext.data.Iterator(val_ds, batch_size=64, train=False, sort=False)\n",
        "test_val = torchtext.data.Iterator(test_ds, batch_size=64, train=False, sort=False)\n",
        "\n",
        "batch = next(iter(val_dl))\n",
        "print(batch.text)\n",
        "print(batch.Label)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[   2,    5,  113,  ...,    1,    1,    1],\n",
            "        [   2,  630, 4808,  ...,    1,    1,    1],\n",
            "        [   2,    6, 1746,  ...,    1,    1,    1],\n",
            "        ...,\n",
            "        [   2,    5,  227,  ...,    1,    1,    1],\n",
            "        [   2,  186,  185,  ...,    1,    1,    1],\n",
            "        [   2,  752,   32,  ...,    1,    1,    1]]), tensor([23,  9, 12, 34, 32, 18, 21, 19, 25, 11, 11, 26, 26, 26, 19, 18, 13,  5,\n",
            "        29, 16, 10, 27, 14, 27, 21, 26, 22, 22, 23, 11, 25, 12, 19, 26, 19, 21,\n",
            "        13, 11, 30, 13, 21, 32, 16, 19, 29, 29, 19, 14, 16, 23, 24, 15, 20, 25,\n",
            "        26, 21, 23, 24, 18,  8, 10, 28, 19, 22]))\n",
            "tensor([3, 1, 1, 5, 5, 4, 3, 0, 3, 3, 3, 5, 4, 3, 4, 3, 3, 3, 5, 3, 0, 1, 5, 4,\n",
            "        3, 3, 5, 4, 5, 4, 4, 4, 4, 5, 1, 1, 3, 3, 4, 5, 2, 1, 3, 5, 3, 3, 5, 5,\n",
            "        3, 3, 3, 3, 0, 4, 4, 3, 5, 3, 3, 3, 1, 4, 1, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWahVTaXj0lc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# パッケージのimport\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "#埋め込み層の定義\n",
        "\n",
        "class Embedder(nn.Module):\n",
        "  def __init__(self, text_embedding_vectors):\n",
        "    super(Embedder, self).__init__()\n",
        "    #freezeで更新をしない\n",
        "    self.embeddings=nn.Embedding.from_pretrained(\n",
        "        embeddings=text_embedding_vectors, freeze=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x_vec = self.embeddings(x)\n",
        "\n",
        "    return x_vec\n",
        "\n",
        "import math\n",
        "class PositionalEncoder(nn.Module):\n",
        "    '''入力された単語の位置を示すベクトル情報を付加する'''\n",
        "\n",
        "    def __init__(self, d_model=300, max_seq_len=256):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model  # 単語ベクトルの次元数\n",
        "\n",
        "        # 単語の順番（pos）と埋め込みベクトルの次元の位置（i）によって一意に定まる値の表をpeとして作成\n",
        "        pe = torch.zeros(max_seq_len, d_model)\n",
        "\n",
        "        # GPUが使える場合はGPUへ送る、実際に学習時には使用する\n",
        "        #学習時以外(動作確認)で使うとerrorでるっぽい？\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        pe = pe.to(device)\n",
        "\n",
        "        for pos in range(max_seq_len):\n",
        "            for i in range(0, d_model, 2):\n",
        "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
        "                pe[pos, i + 1] = math.cos(pos /\n",
        "                                          (10000 ** ((2 * (i + 1))/d_model)))\n",
        "\n",
        "        # 表peの先頭に、ミニバッチ次元となる次元を足す\n",
        "        self.pe = pe.unsqueeze(0)\n",
        "\n",
        "        # 勾配を計算しないようにする\n",
        "        self.pe.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # 入力xとPositonal Encodingを足し算する\n",
        "        # xがpeよりも小さいので、大きくする\n",
        "        ret = math.sqrt(self.d_model)*x + self.pe\n",
        "        return ret\n",
        "    \n",
        "class Attention(nn.Module):\n",
        "  def __init__(self, d_model=300):\n",
        "    super().__init__()\n",
        "\n",
        "    #query, value, keyを出力\n",
        "    self.q_linear = nn.Linear(d_model, d_model)\n",
        "    self.v_linear = nn.Linear(d_model, d_model)\n",
        "    self.k_linear = nn.Linear(d_model, d_model)\n",
        "\n",
        "    #ここは最後のoutput\n",
        "    self.out = nn.Linear(d_model, d_model)\n",
        "\n",
        "    self.d_k = d_model\n",
        "\n",
        "  def forward(self, q, k, v, mask):\n",
        "    #query, value, keyを出力\n",
        "    k = self.k_linear(k)\n",
        "    q = self.q_linear(q)\n",
        "    v = self.v_linear(v)\n",
        "\n",
        "    #queryに対するmemoryの関連度を計算している, 大きさの制限もかけている\n",
        "    weights = torch.matmul(q, k.transpose(1, 2)) / math.sqrt(self.d_k)\n",
        "\n",
        "    mask = mask.unsqueeze(1)\n",
        "    #mask部分を-infで置き換え\n",
        "    weights = weights.masked_fill(mask==0, -1e9)\n",
        "\n",
        "    \"\"\"\n",
        "    softmaxで関連度を正規化\n",
        "    ここはshapeが(queryの単語数,　memoryの単語数)になっており\n",
        "    各行はqueryに対して各memoryの関連度(のようなもの)を表している\n",
        "    これを関数から出力することで可視化に使っている。\n",
        "    \"\"\"\n",
        "    normlized_weights = F.softmax(weights, dim=-1)\n",
        "\n",
        "    #Attention\n",
        "    output = torch.matmul(normlized_weights, v)\n",
        "    output = self.out(output)\n",
        "\n",
        "    return output, normlized_weights\n",
        "  \n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff=1024, dropout=0.1):\n",
        "        '''Attention層から出力を単純に全結合層2つで特徴量を変換するだけのユニットです'''\n",
        "        super().__init__()\n",
        "\n",
        "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear_1(x)\n",
        "        x = self.dropout(F.relu(x))\n",
        "        x = self.linear_2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # LayerNormalization層\n",
        "        # https://pytorch.org/docs/stable/nn.html?highlight=layernorm\n",
        "        self.norm_1 = nn.LayerNorm(d_model)\n",
        "        self.norm_2 = nn.LayerNorm(d_model)\n",
        "\n",
        "        # Attention層\n",
        "        self.attn = Attention(d_model)\n",
        "\n",
        "        # Attentionのあとの全結合層2つ\n",
        "        self.ff = FeedForward(d_model)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout_1 = nn.Dropout(dropout)\n",
        "        self.dropout_2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # 正規化とAttention\n",
        "        x_normlized = self.norm_1(x)\n",
        "        output, normlized_weights = self.attn(\n",
        "            x_normlized, x_normlized, x_normlized, mask)\n",
        "        \n",
        "        x2 = x + self.dropout_1(output)\n",
        "\n",
        "        # 正規化と全結合層\n",
        "        x_normlized2 = self.norm_2(x2)\n",
        "        output = x2 + self.dropout_2(self.ff(x_normlized2))\n",
        "\n",
        "        return output, normlized_weights\n",
        "  \n",
        "class ClassificationHead(nn.Module):\n",
        "  def __init__(self, d_model=300, output_dim=5):\n",
        "    super().__init__()\n",
        "\n",
        "    self.linear = nn.Linear(d_model, output_dim)\n",
        "    \n",
        "    nn.init.normal_(self.linear.weight, std=0.02)\n",
        "    nn.init.normal_(self.linear.bias, 0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #各バッチの<cls>の特徴量を抽出する\n",
        "    x0 = x[:, 0, :]\n",
        "    out = self.linear(x0)\n",
        "\n",
        "    return out\n",
        "\n",
        "class TransformerClassification(nn.Module):\n",
        "  def __init__(self, text_embedding_vectors, d_model=300, max_seq_len=140,\n",
        "               output_dim=5):\n",
        "    super().__init__()\n",
        "\n",
        "    self.net1 = Embedder(text_embedding_vectors)\n",
        "    self.net2 = PositionalEncoder(d_model=d_model, max_seq_len=max_seq_len)\n",
        "    self.net3_1 = TransformerBlock(d_model=d_model)\n",
        "    self.net3_2 = TransformerBlock(d_model=d_model)\n",
        "    self.net4 = ClassificationHead(output_dim=output_dim, d_model=d_model)\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    x1 = self.net1(x)\n",
        "    x2 = self.net2(x1)\n",
        "    x3_1, normlized_weights_1 = self.net3_1(x2, mask)\n",
        "    x3_2, normlized_weights_2 = self.net3_2(x3_1, mask)\n",
        "    x4 = self.net4(x3_2,)\n",
        "    return x4, normlized_weights_1, normlized_weights_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkPu5ImckMx_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b434edb2-8e89-4dd4-981a-e2a3fe57bc0b"
      },
      "source": [
        "# 辞書オブジェクトにまとめる\n",
        "dataloaders_dict = {\"train\": train_dl, \"val\": val_dl}\n",
        "# モデル構築\n",
        "net = TransformerClassification(\n",
        "    text_embedding_vectors=TEXT.vocab.vectors, d_model=300, max_seq_len=142, output_dim=6)\n",
        "\n",
        "# ネットワークの初期化を定義\n",
        "\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Linear') != -1:\n",
        "        # Liner層の初期化\n",
        "        nn.init.kaiming_normal_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias, 0.0)\n",
        "\n",
        "\n",
        "# 訓練モードに設定\n",
        "net.train()\n",
        "\n",
        "# TransformerBlockモジュールを初期化実行\n",
        "net.net3_1.apply(weights_init)\n",
        "net.net3_2.apply(weights_init)\n",
        "\n",
        "\n",
        "print('ネットワーク設定完了')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ネットワーク設定完了\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gUH7Zk0kXDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#最適化手法\n",
        "learning_rate = 2e-5\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hxq1vN4Fkcnn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#モデルを訓練して、訓練したモデルをreturnする\n",
        "#モデル、辞書型で定義したdataloder(イテレータ)、損失関数、オプティマイザ、エポック数を渡す\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    # GPUが使えるかを確認\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"使用デバイス：\", device)\n",
        "    print('-----start-------')\n",
        "    # モデルをGPUへ渡す\n",
        "    net.to(device)\n",
        "\n",
        "    # ネットワークがある程度固定であれば、高速化させる\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # 各epoch\n",
        "    for epoch in range(num_epochs):\n",
        "        # 学習と検証\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()  # モデルを訓練モードに\n",
        "            else:\n",
        "                net.eval()   # モデルを検証モードに\n",
        "\n",
        "            epoch_loss = 0.0  # epochの損失和\n",
        "            epoch_corrects = 0  # epochの正解数\n",
        "\n",
        "            # 各バッチ\n",
        "            for batch in (dataloaders_dict[phase]):\n",
        "                # batchはTextとLableの辞書オブジェクト\n",
        "\n",
        "                # GPUが使えるならGPUにデータを送る\n",
        "                inputs = batch.text[0].to(device)  # 文章\n",
        "                labels = batch.Label.to(device)  # ラベル\n",
        "\n",
        "                # optimizerを初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                    # mask作成\n",
        "                    input_pad = 1  # 単語のIDにおいて、'<pad>': 1 なので\n",
        "                    input_mask = (inputs != input_pad) #mask部分がFalseに\n",
        "\n",
        "                    # モデルに入力\n",
        "                    outputs, _, _ = net(inputs, input_mask)\n",
        "                    loss = criterion(outputs, labels)  # 損失を計算\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "\n",
        "                    # 訓練時はバックプロパゲーション\n",
        "                    if phase == 'train':\n",
        "                        #勾配を計算\n",
        "                        loss.backward()\n",
        "                        #パラメータの更新\n",
        "                        optimizer.step()\n",
        "\n",
        "                    # 結果の計算\n",
        "                    epoch_loss += loss.item() * inputs.size(0)  # lossの合計を更新\n",
        "                    # 正解数の合計を更新\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # epochごとのlossと正解率\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = epoch_corrects.double(\n",
        "            ) / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "            print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
        "                                                                           phase, epoch_loss, epoch_acc))\n",
        "\n",
        "    return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1ub8Vg7kmT8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "44561a64-9659-455b-f8a8-df84bcffc980"
      },
      "source": [
        "import torch.nn.functional as F \n",
        "num_epochs = 10\n",
        "net_trained = train_model(net, dataloaders_dict,\n",
        "                          criterion, optimizer, num_epochs=num_epochs)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "使用デバイス： cuda:0\n",
            "-----start-------\n",
            "Epoch 1/10 | train |  Loss: 1.6014 Acc: 0.3873\n",
            "Epoch 1/10 |  val  |  Loss: 1.3968 Acc: 0.4697\n",
            "Epoch 2/10 | train |  Loss: 1.3953 Acc: 0.4689\n",
            "Epoch 2/10 |  val  |  Loss: 1.3221 Acc: 0.4960\n",
            "Epoch 3/10 | train |  Loss: 1.3134 Acc: 0.4962\n",
            "Epoch 3/10 |  val  |  Loss: 1.2565 Acc: 0.5214\n",
            "Epoch 4/10 | train |  Loss: 1.2584 Acc: 0.5231\n",
            "Epoch 4/10 |  val  |  Loss: 1.2333 Acc: 0.5277\n",
            "Epoch 5/10 | train |  Loss: 1.2218 Acc: 0.5382\n",
            "Epoch 5/10 |  val  |  Loss: 1.2022 Acc: 0.5319\n",
            "Epoch 6/10 | train |  Loss: 1.1942 Acc: 0.5525\n",
            "Epoch 6/10 |  val  |  Loss: 1.1908 Acc: 0.5377\n",
            "Epoch 7/10 | train |  Loss: 1.1708 Acc: 0.5608\n",
            "Epoch 7/10 |  val  |  Loss: 1.1898 Acc: 0.5383\n",
            "Epoch 8/10 | train |  Loss: 1.1540 Acc: 0.5667\n",
            "Epoch 8/10 |  val  |  Loss: 1.1759 Acc: 0.5536\n",
            "Epoch 9/10 | train |  Loss: 1.1356 Acc: 0.5762\n",
            "Epoch 9/10 |  val  |  Loss: 1.1709 Acc: 0.5515\n",
            "Epoch 10/10 | train |  Loss: 1.1222 Acc: 0.5790\n",
            "Epoch 10/10 |  val  |  Loss: 1.1652 Acc: 0.5530\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_0AVG8bkoV5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99a17dbd-3c9e-46fe-da52-3440522c56aa"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "net_trained.eval()\n",
        "net_trained.to(device)\n",
        "\n",
        "y_true = np.array([])\n",
        "y_pred = np.array([])\n",
        "\n",
        "epoch_corrects = 0\n",
        "\n",
        "for batch in (test_val):\n",
        "  inputs = batch.text[0].to(device)\n",
        "  labels = batch.Label.to(device)\n",
        "\n",
        "  with torch.set_grad_enabled(False):\n",
        "    input_pad = 1\n",
        "    input_mask = (inputs != input_pad)\n",
        "\n",
        "    outputs, _, _ = net_trained(inputs, input_mask)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    \n",
        "    y_true = np.concatenate([y_true, labels.to(\"cpu\", torch.double).numpy()])\n",
        "    y_pred = np.concatenate([y_pred, preds.to(\"cpu\", torch.double).numpy()])\n",
        "\n",
        "    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "# 正解率\n",
        "epoch_acc = epoch_corrects.double() / len(test_val.dataset)\n",
        "\n",
        "print('テストデータ{}個での正解率：{:.4f}'.format(len(test_val.dataset),epoch_acc))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "テストデータ2106個での正解率：0.5726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoGPoSg_lPCC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "80f04265-5a5f-4ccc-8a26-3e15d7059a05"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=['怒り', '恐怖', '嫌悪','喜び', '悲しみ', '驚き']))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          怒り       0.52      0.38      0.44       156\n",
            "          恐怖       0.68      0.51      0.59       282\n",
            "          嫌悪       0.35      0.12      0.18        76\n",
            "          喜び       0.63      0.80      0.70       824\n",
            "         悲しみ       0.46      0.40      0.42       383\n",
            "          驚き       0.49      0.48      0.49       385\n",
            "\n",
            "    accuracy                           0.57      2106\n",
            "   macro avg       0.52      0.45      0.47      2106\n",
            "weighted avg       0.56      0.57      0.56      2106\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8MregDSliWe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "outputId": "de494430-a2ca-4843-9998-df44f270fbf0"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "confmat = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
        "fig, ax = plt.subplots(figsize=(2.5, 2.5))\n",
        "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(confmat.shape[0]):\n",
        "    for j in range(confmat.shape[1]):\n",
        "        ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
        "\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "\n",
        "plt.tight_layout()\n",
        "#plt.savefig('confusion_matrix.png', dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 180x180 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0rHCf9zlqcX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}